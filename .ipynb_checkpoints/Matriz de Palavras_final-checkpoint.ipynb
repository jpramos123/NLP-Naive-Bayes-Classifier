{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador Bayesiano\n",
    "\n",
    "Nome: Joao Paulo Ramos\n",
    "\n",
    "Disciplina: Processamento de Linguagem Natural - PEL218\n",
    "\n",
    "### Objetivo Geral\n",
    "\n",
    "Criar uma classificador Bayesiano capaz de discriminar uma frase entre pedofilia e não pedofilia\n",
    "\n",
    "#### Etapa 1:\n",
    "Criar uma matriz com todas as palavras represtadas pelas colunas e linhas de uma matriz, \n",
    "e também os sinalizadores de contextos C0 e C1 como as ultimas colunas e linhas dessa matriz:\n",
    "\n",
    "```\n",
    "W1 W2 W3 W4 Wn C0 C1\n",
    "W1 \n",
    "W2\n",
    "W3\n",
    "W4\n",
    "Wn\n",
    "C0\n",
    "C1\n",
    "```\n",
    "\n",
    "#### Etapa 2:\n",
    "\n",
    "Criar a interseção entre as palavras vizinhas\n",
    "\n",
    "Essa matriz representa as conexões entre as palavras em um determinado contexto, gerando um grafo.\n",
    "\n",
    "#### Etapa 3:\n",
    "\n",
    "Criar um classificador Bayesiano\n",
    "\n",
    "#### Etapa 4:\n",
    "\n",
    "Otimizar o modelo.\n",
    "\n",
    "\n",
    "#### Base de dados: PAN12 Sexual Predator Identification\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Datasets-Conversas/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chat_id</th>\n",
       "      <th>line</th>\n",
       "      <th>message</th>\n",
       "      <th>author</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>14122</td>\n",
       "      <td>105</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f42a87add1c0f6f6f752f9977c8bbee2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>13563</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3386750395d5990bd23374458798ebc4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>12072</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ed468ccaa6af71a54cbda2f679ab561f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>6509</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3b61d601bef810d07597f61920ea8754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>13387</td>\n",
       "      <td>102</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feac11cb12e33e40fe9d947bb717d610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>12124</td>\n",
       "      <td>93</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8e150ba782a5db40ac530026fc101e6a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>10466</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b90a6be98116427a5580cf32cedaf55c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6620</th>\n",
       "      <td>12004</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ed468ccaa6af71a54cbda2f679ab561f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>18913</td>\n",
       "      <td>150</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7dc05d1cf558bd2e5548fda49aef7371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>10285</td>\n",
       "      <td>81</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2f14cad7debebf2e57fa480e7a27b307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12777</th>\n",
       "      <td>5061</td>\n",
       "      <td>58</td>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd593beb13c7b187d70bbefe3b1b88c5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13035</th>\n",
       "      <td>19376</td>\n",
       "      <td>152</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78391675dd3c9ddec2c538e14d9de059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  chat_id  line message                            author  \\\n",
       "803         14122      105    51     NaN  f42a87add1c0f6f6f752f9977c8bbee2   \n",
       "3338        13563      103   110     NaN  3386750395d5990bd23374458798ebc4   \n",
       "3710        12072       93    77     NaN  ed468ccaa6af71a54cbda2f679ab561f   \n",
       "3776         6509       66    20     NaN  3b61d601bef810d07597f61920ea8754   \n",
       "3836        13387      102   110     NaN  feac11cb12e33e40fe9d947bb717d610   \n",
       "4720        12124       93   129     NaN  8e150ba782a5db40ac530026fc101e6a   \n",
       "5312        10466       82    17     NaN  b90a6be98116427a5580cf32cedaf55c   \n",
       "6620        12004       93     9     NaN  ed468ccaa6af71a54cbda2f679ab561f   \n",
       "7997        18913      150    82     NaN  7dc05d1cf558bd2e5548fda49aef7371   \n",
       "12309       10285       81    28     NaN  2f14cad7debebf2e57fa480e7a27b307   \n",
       "12777        5061       58   144     NaN  cd593beb13c7b187d70bbefe3b1b88c5   \n",
       "13035       19376      152   125     NaN  78391675dd3c9ddec2c538e14d9de059   \n",
       "\n",
       "       type  \n",
       "803       0  \n",
       "3338      0  \n",
       "3710      0  \n",
       "3776      0  \n",
       "3836      0  \n",
       "4720      0  \n",
       "5312      0  \n",
       "6620      0  \n",
       "7997      0  \n",
       "12309     0  \n",
       "12777     0  \n",
       "13035     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['message'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpa  texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jramos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    html_free = soup.text\n",
    "    return html_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    clean_txt = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopWords(text):\n",
    "    phrase = [w.lower() for w in text.split() if w not in stopwords.words('portuguese')]\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(phrase, graph, reverse_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "        Essa função é o classificador bayesiano.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    ctx_1_weight = graph[:, -2].sum()\n",
    "    ctx_2_weight = graph[:, -1].sum()\n",
    "    product_ctx_1 = 0\n",
    "    product_ctx_2 = 0\n",
    "    \n",
    "    if len(phrase) > 0:\n",
    "        for word in phrase:\n",
    "            try:\n",
    "                word_idx = reverse_dict[word]\n",
    "            except KeyError:\n",
    "                word_idx = 1\n",
    "\n",
    "            #print(word_idx)\n",
    "            #Classificação do contexto 1\n",
    "            word_to_ctx_1 = graph[word_idx][-2]\n",
    "            if word_to_ctx_1 != 0:\n",
    "                product_ctx_1 = np.log((word_to_ctx_1/ctx_1_weight)) + product_ctx_1\n",
    "            #print(product_ctx_1)\n",
    "\n",
    "            #Classificação do contexto 2\n",
    "            word_to_ctx_2 = graph[word_idx][-1]        \n",
    "\n",
    "            if word_to_ctx_2 != 0:\n",
    "                product_ctx_2 = np.log((word_to_ctx_2/ctx_2_weight)) + product_ctx_2\n",
    "            #print(product_ctx_2)\n",
    "            \n",
    "            try:\n",
    "                product_ctx_1 = np.exp(product_ctx_1)\n",
    "                product_ctx_2 = np.exp(product_ctx_2)\n",
    "            except OverflowError:\n",
    "                print(\"Overflow Error occured\")\n",
    "                return -1\n",
    "\n",
    "        probability_ctx_1 = product_ctx_1/(product_ctx_1 + product_ctx_2)\n",
    "        probability_ctx_2 = product_ctx_2/(product_ctx_1 + product_ctx_2)\n",
    "\n",
    "        if probability_ctx_1 > probability_ctx_2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(lambda text: remove_html(text))\n",
    "\n",
    "data['message'] = data['message'].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "data['message'] = data['message'].apply(lambda text: remove_stopWords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chat_id</th>\n",
       "      <th>line</th>\n",
       "      <th>message</th>\n",
       "      <th>author</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21003</td>\n",
       "      <td>159</td>\n",
       "      <td>235</td>\n",
       "      <td>[quê]</td>\n",
       "      <td>31983229136ed17d79c70bd991d419ef</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7378</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>[pois, luzinhas, intensidade, som, tá, captand...</td>\n",
       "      <td>a90ceef513df19ef7fee7b872f733e4a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10892</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>[uai]</td>\n",
       "      <td>8e150ba782a5db40ac530026fc101e6a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20247</td>\n",
       "      <td>155</td>\n",
       "      <td>92</td>\n",
       "      <td>[vai, bora, faz, muita, força, aqui]</td>\n",
       "      <td>94eb8c17d07f1ed9ddfff352e22e6675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10890</td>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>[ainda, fala, assim, gente, xinga, pessoa, tá,...</td>\n",
       "      <td>8e150ba782a5db40ac530026fc101e6a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  chat_id  line  \\\n",
       "0       21003      159   235   \n",
       "1        7378       70    67   \n",
       "2       10892       83    77   \n",
       "3       20247      155    92   \n",
       "4       10890       83    75   \n",
       "\n",
       "                                             message  \\\n",
       "0                                              [quê]   \n",
       "1  [pois, luzinhas, intensidade, som, tá, captand...   \n",
       "2                                              [uai]   \n",
       "3               [vai, bora, faz, muita, força, aqui]   \n",
       "4  [ainda, fala, assim, gente, xinga, pessoa, tá,...   \n",
       "\n",
       "                             author  type  \n",
       "0  31983229136ed17d79c70bd991d419ef     0  \n",
       "1  a90ceef513df19ef7fee7b872f733e4a     0  \n",
       "2  8e150ba782a5db40ac530026fc101e6a     0  \n",
       "3  94eb8c17d07f1ed9ddfff352e22e6675     0  \n",
       "4  8e150ba782a5db40ac530026fc101e6a     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma as frases por linha em palavras por linha\n",
    "word_type = pd.DataFrame(data['message'].apply(pd.Series,1).stack())\n",
    "word_type = word_type.droplevel(1)\n",
    "word_type = word_type.merge(data['type'].to_frame(),  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_type.rename(columns={0:\"words\", \"type\":\"context\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dicionario de indice:palavra\n",
    "unique_words = word_type['words'].unique()\n",
    "reverse_dict = {unique_words[i]:i for i in range(len(unique_words))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constroi Grafo de palavras (2-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(row, graph, reverse_dict):\n",
    "    phrase = row['message']\n",
    "    context = row['type']\n",
    "    for j in range(len(phrase)):\n",
    "        \n",
    "        # Valida se a palavra atual tem vizinho\n",
    "        if j+1 >= len(phrase):\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            # Se tem vizinho, incrementa na interseção\n",
    "            graph[reverse_dict[phrase[j]]][reverse_dict[phrase[j+1]]] += 1\n",
    "            graph[reverse_dict[phrase[j+1]]][reverse_dict[phrase[j]]] += 1\n",
    "            # Verifica o contexto das palavras e aplica na matriz\n",
    "            if context == 0:\n",
    "                ctx = -2\n",
    "                graph[reverse_dict[phrase[j]]][ctx] += 1\n",
    "                graph[ctx][reverse_dict[phrase[j]]] += 1\n",
    "                graph[reverse_dict[phrase[j+1]]][ctx] += 1\n",
    "                graph[ctx][reverse_dict[phrase[j+1]]] += 1\n",
    "            else:\n",
    "                ctx = -1\n",
    "                graph[reverse_dict[phrase[j]]][ctx] += 1\n",
    "                graph[ctx][reverse_dict[phrase[j]]] += 1\n",
    "                graph[reverse_dict[phrase[j+1]]][ctx] += 1\n",
    "                graph[ctx][reverse_dict[phrase[j+1]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.zeros((len(unique_words)+2, len(unique_words)+2), dtype=int)\n",
    "data.apply(lambda row: buildGraph(row, graph, reverse_dict), axis=1)\n",
    "gp_norm = preprocessing.normalize(graph, 'l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa etapa é feita a classificação do modelo, utilizando a base de teste e o classificador Bayesiano\n",
    "\n",
    "Podemos observar que o modelo tem uma precisão baixa, de 16.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./Datasets-Conversas/test.csv')\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['message'] = test_data['message'].apply(lambda text: remove_html(text))\n",
    "\n",
    "test_data['message'] = test_data['message'].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "test_data['message'] = test_data['message'].apply(lambda text: remove_stopWords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_classifed = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "test_data_classifed['pred'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm, reverse_dict), axis=1)\n",
    "score = accuracy_score(test_data_classifed['type'], test_data_classifed['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão final:  16.529789457966253\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisão final: \", score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização do Modelo\n",
    "\n",
    "Para melhorar a precisão do modelo, aumentei o grau do grafo para que o mesmo encontre conexões diferentes entre as palavras (que são os nós do grafo).\n",
    "\n",
    "Para aumentar o grau do grafo devemos seguir as seguintes etapas:\n",
    "\n",
    "1) Salvar o grafo inicial\n",
    "\n",
    "2) Multiplicar o grafo por ele mesmo\n",
    "\n",
    "3) Somar o resultado da multiplicação com o grafo inicial\n",
    "\n",
    "4) Normalizar o grafo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Matrix Degree (n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de codigo para gerar um grafo N=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gp_norm = np.load('graph_pot_2.npy')\n",
    "except:\n",
    "    graph = gp_norm.copy()\n",
    "    for i in range(2):\n",
    "        new_graph_pot = graph\n",
    "        graph_pot = np.matmul(new_graph_pot, new_graph_pot)\n",
    "        graph = graph_pot + new_graph_pot\n",
    "        graph = preprocessing.normalize(graph, 'l1')\n",
    "\n",
    "    np.save('graph_pot_2.npy', graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo estão os grafos com o aumento de grau ja feito, pois essa multiplicação exige tempo e poder computacional para ser feita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "gp_norm2 = np.load(\"graph_pot_0.npy\")\n",
    "\n",
    "gp_norm3 = np.load(\"graph_pot_1.npy\")\n",
    "\n",
    "gp_norm4 = np.load(\"graph_pot_2.npy\")\n",
    "\n",
    "gp_norm5 = np.load(\"graph_pot_3.npy\")\n",
    "\n",
    "gp_norm6 = np.load(\"graph_pot_4.npy\")\n",
    "\n",
    "gp_norm7 = np.load(\"graph_pot_5.npy\")\n",
    "\n",
    "test_data_classifed['pred_2'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm2, reverse_dict), axis=1)\n",
    "\n",
    "test_data_classifed['pred_3'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm3, reverse_dict), axis=1)\n",
    "\n",
    "test_data_classifed['pred_4'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm4, reverse_dict), axis=1)\n",
    "\n",
    "test_data_classifed['pred_5'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm5, reverse_dict), axis=1)\n",
    "\n",
    "test_data_classifed['pred_6'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm6, reverse_dict), axis=1)\n",
    "\n",
    "test_data_classifed['pred_7'] = test_data_classifed.apply(lambda row: classify(row['message'], gp_norm7, reverse_dict), axis=1)\n",
    "\n",
    "score = accuracy_score(test_data_classifed['type'], test_data_classifed['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_2'])\n",
    "score3 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_3'])\n",
    "score4 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_4'])\n",
    "score5 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_5'])\n",
    "score6 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_6'])\n",
    "score7 = accuracy_score(test_data_classifed['type'], test_data_classifed['pred_7'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado da otimização\n",
    "\n",
    "Com a otimização podemos observar um aumento significativo da classificação do modelo.\n",
    "\n",
    "O modelo parece convergir quando N=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1 16.529789457966253\n",
      "N=2 76.88517246528296\n",
      "N=3 80.63311930715246\n",
      "N=4 79.78199193668807\n",
      "N=5 79.60280722711663\n",
      "N=6 79.60280722711663\n",
      "N=7 80.5883231297596\n"
     ]
    }
   ],
   "source": [
    "print(\"N=1\", score*100)\n",
    "print(\"N=2\", score0*100)\n",
    "print(\"N=3\", score1*100)\n",
    "print(\"N=4\", score2*100)\n",
    "print(\"N=5\",score3*100)\n",
    "print(\"N=6\",score4*100)\n",
    "print(\"N=7\",score5*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
